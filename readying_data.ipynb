{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a07489",
   "metadata": {},
   "source": [
    "# Preparing parquet files for sql loading\n",
    "\n",
    "- From each lookup table, deduplicate and get the unique values.\n",
    "- Assign those values an id\n",
    "- These will server for your lookup tables\n",
    "\n",
    "- Map those back to the main file\n",
    "- You merge them back to your big file, to replace raw columns, with the corresponding IDs\n",
    "\n",
    "- shipments table will have all these generated ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef279d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import dask.dataframe as dd\n",
    "chunksize = 400_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b07f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_fps_2019_cargodesc = [\n",
    "    \"./data/cleaned/2019/cargodesc_files/ams_cargodesc_2019_part_0.parquet\",\n",
    "    \"./data/cleaned/2019/cargodesc_files/ams_cargodesc_2019_part_1.parquet\",\n",
    "    \"./data/cleaned/2019/cargodesc_files/ams_cargodesc_2019_part_2.parquet\",\n",
    "    \"./data/cleaned/2019/cargodesc_files/ams_cargodesc_2019_part_3.parquet\",\n",
    "    \"./data/cleaned/2019/cargodesc_files/ams_cargodesc_2019_part_4.parquet\"\n",
    "]\n",
    "\n",
    "\n",
    "cleaned_fps_2019_header = [\n",
    "    \"./data/cleaned/2019/header_files/ams_header_2019_part_0.parquet\",\n",
    "    \"./data/cleaned/2019/header_files/ams_header_2019_part_1.parquet\",\n",
    "    \"./data/cleaned/2019/header_files/ams_header_2019_part_2.parquet\",\n",
    "    \"./data/cleaned/2019/header_files/ams_header_2019_part_3.parquet\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9401397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_fps_2020_cargodesc = [\n",
    "    \"./data/cleaned/2020/cargodesc_files/ams_cargodesc_2020_part_0.parquet\",\n",
    "    \"./data/cleaned/2020/cargodesc_files/ams_cargodesc_2020_part_1.parquet\",\n",
    "    \"./data/cleaned/2020/cargodesc_files/ams_cargodesc_2020_part_2.parquet\",\n",
    "    \"./data/cleaned/2020/cargodesc_files/ams_cargodesc_2020_part_3.parquet\"\n",
    "\n",
    "]\n",
    "\n",
    "cleaned_fps_2020_header = [\n",
    "    \"./data/cleaned/2020/header_files/ams_header_2020_part_0.parquet\",\n",
    "    \"./data/cleaned/2020/header_files/ams_header_2020_part_1.parquet\",\n",
    "    \"./data/cleaned/2020/header_files/ams_header_2020_part_2.parquet\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fee42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting unique values for lookup tables\n",
    "\n",
    "# Lookup table 1\n",
    "unique_cargo_desc = set()\n",
    "\n",
    "# Lookup table 2\n",
    "unique_port_lading_info = set()\n",
    "unique_port_unlading_info = set()\n",
    "\n",
    "# Lookup table 3\n",
    "unique_arrival_date_info = set()\n",
    "unique_estimated_date_info = set()\n",
    "\n",
    "unique_weight_info = set() # Lookup table 4\n",
    "unique_weight_unit = set()\n",
    "\n",
    "unique_manifest_quant = set() # Lookup table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting unique values for lookup table cargodesc\n",
    "for fp in cleaned_fps_2020_cargodesc:\n",
    "    ddf = dd.read_parquet(fp,columns=['description_text'])\n",
    "    uniques = ddf['description_text'].compute()\n",
    "    unique_cargo_desc.update(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff77555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all unique actual arrival dates and unique estimated arrival dates\n",
    "\n",
    "for fp in cleaned_fps_2020_header:\n",
    "    ddf = dd.read_parquet(fp,columns=['estimated_arrival_date','actual_arrival_date'])\n",
    "    \n",
    "    unique_actual = ddf['actual_arrival_date'].drop_duplicates().compute()\n",
    "    unique_estimated = ddf['estimated_arrival_date'].drop_duplicates().compute()\n",
    "\n",
    "    unique_arrival_date_info.update(unique_actual)\n",
    "    unique_estimated_date_info.update(unique_estimated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f0560d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fp in cleaned_fps_2020_header:\n",
    "    ddf = dd.read_parquet(fp,columns=['port_of_unlading','foreign_port_of_lading'])\n",
    "\n",
    "    unique_ports_u = ddf['port_of_unlading'].drop_duplicates().compute()\n",
    "    unique_port_l = ddf['foreign_port_of_lading'].drop_duplicates().compute()\n",
    "\n",
    "    unique_port_unlading_info.update(unique_ports_u)\n",
    "    unique_port_lading_info.update(unique_port_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7400622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting unique weights and units\n",
    "for fp in cleaned_fps_2020_header:\n",
    "    ddf = dd.read_parquet(fp,columns=['weight','weight_unit'])\n",
    "\n",
    "    unique_weight = ddf['weight'].drop_duplicates().compute()\n",
    "    unique_unit = ddf['weight_unit'].drop_duplicates().compute()\n",
    "\n",
    "    unique_weight_info.update(unique_weight)\n",
    "    unique_weight_unit.update(unique_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7724a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting quantity of items per shipment\n",
    "for fp in cleaned_fps_2020_header:\n",
    "    ddf = dd.read_parquet(fp,columns=['manifest_quantity'])\n",
    "\n",
    "    unique_quant = ddf['manifest_quantity'].drop_duplicates().compute()\n",
    "    unique_manifest_quant.update(unique_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5fb756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing empty lists, memory purposes\n",
    "cargo_desc_sorted = []\n",
    "port_lading_sorted = []\n",
    "port_unlading_sorted = []\n",
    "arrival_date_sorted = []\n",
    "estimated_date_sorted = []\n",
    "weight_sorted = []\n",
    "weight_unit_sorted = []\n",
    "manisfest_unit_sorted = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e7aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making lookup tables\n",
    "# sort sets first, creating stable ids\n",
    "\n",
    "cargo_desc_sorted = sorted(unique_cargo_desc)\n",
    "port_lading_sorted = sorted(unique_port_lading_info)\n",
    "port_unlading_sorted = sorted(unique_port_unlading_info)\n",
    "arrival_date_sorted = sorted(unique_arrival_date_info)\n",
    "estimated_date_sorted = sorted(unique_estimated_date_info)\n",
    "weight_sorted = sorted(unique_weight_info)\n",
    "weight_unit_sorted = sorted(unique_weight_unit)\n",
    "manisfest_unit_sorted = sorted(unique_manifest_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19e6648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the lookup tables\n",
    "\n",
    "cargo_desc_lookup = pd.DataFrame({\n",
    "    'cargodesc_id': range(1,len(cargo_desc_sorted) + 1),\n",
    "    'cargodesc' : cargo_desc_sorted\n",
    "})\n",
    "\n",
    "port_lading_lookup = pd.DataFrame({\n",
    "    'port_lading_id': range(1,len(port_lading_sorted) + 1),\n",
    "    'port_of_lading': port_lading_sorted\n",
    "})\n",
    "\n",
    "port_unlading_lookup = pd.DataFrame({\n",
    "    'port_unlading_id' : range(1, len(port_unlading_sorted) + 1),\n",
    "    'port_of_unlading' : port_unlading_sorted\n",
    "})\n",
    "\n",
    "arrival_date_lookup = pd.DataFrame({\n",
    "    'arrival_id': range(1, len(arrival_date_sorted) + 1),\n",
    "    'arrival_date': arrival_date_sorted\n",
    "})\n",
    "\n",
    "estimated_arrival_lookup = pd.DataFrame({\n",
    "    'estimated_arrival_id': range(1,len(estimated_date_sorted) + 1),\n",
    "    'estimated_arrival_date': estimated_date_sorted\n",
    "})\n",
    "\n",
    "weight_lookup = pd.DataFrame({\n",
    "    'weight_id': range(1,len(weight_sorted) + 1),\n",
    "    'weight': weight_sorted\n",
    "})\n",
    "\n",
    "weight_unit_lookup = pd.DataFrame({\n",
    "    'weight_unit_id': range(1,len(weight_unit_sorted) + 1),\n",
    "    'weight_unit':weight_unit_sorted\n",
    "})\n",
    "\n",
    "manifest_unit_lookup = pd.DataFrame({\n",
    "    'manifest_quantity_id': range(1,len(unique_manifest_quant) + 1),\n",
    "    'manifest_quantity': manisfest_unit_sorted\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd69920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lookup tables should be their own seperate files\n",
    "\n",
    "cargo_desc_lookup.to_csv('cargo_desc_lookup.csv',index=False)\n",
    "port_lading_lookup.to_csv('port_of_lading_lookup.csv',index=False)\n",
    "port_unlading_lookup.to_csv('port_of_unlading.csv',index=False)\n",
    "arrival_date_lookup.to_csv('arrival_date_lookup.csv',index=False)\n",
    "estimated_arrival_lookup.to_csv('estimated_arrival_lookup.csv',index=False)\n",
    "weight_lookup.to_csv('weight_lookup.csv',index=False)\n",
    "weight_unit_lookup.to_csv('weight_unit_lookup.csv',index=False)\n",
    "manifest_unit_lookup.to_csv('manifest_units_lookup.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e29c2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating mapping ids for fast lookups\n",
    "\n",
    "cargo_mapping = dict(zip(cargo_desc_lookup['cargodesc'], cargo_desc_lookup['cargodesc_id']))\n",
    "\n",
    "port_lading_mapping = dict(zip(port_lading_lookup['port_of_lading'], port_lading_lookup['port_lading_id']))\n",
    "\n",
    "port_unlading_mapping = dict(zip(port_unlading_lookup['port_of_unlading'], port_unlading_lookup['port_unlading_id']))\n",
    "\n",
    "arrival_mapping = dict(zip(arrival_date_lookup['arrival_date'], arrival_date_lookup['arrival_id']))\n",
    "\n",
    "estimated_arrival_mapping = dict(zip(estimated_arrival_lookup['estimated_arrival_date'], estimated_arrival_lookup['estimated_arrival_id']))\n",
    "\n",
    "weight_mapping = dict(zip(weight_lookup['weight'], weight_lookup['weight_id']))\n",
    "\n",
    "weight_unit_mapping = dict(zip(weight_unit_lookup['weight_unit'], weight_unit_lookup['weight_unit_id']))\n",
    "\n",
    "manifest_unit_mapping = dict(zip(manifest_unit_lookup['manifest_quantity'],manifest_unit_lookup['manifest_quantity_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85f01203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be merging everything into the header files where the bulk of the data is\n",
    "# So we make header dfs for our purposes\n",
    "\n",
    "idx = 0\n",
    "for file in cleaned_fps_2020_header:\n",
    "    df = pd.read_parquet(file)\n",
    "\n",
    "    df['port_lading_id'] = df['foreign_port_of_lading'].map(port_lading_mapping)\n",
    "    df['port_unlading_id'] = df['port_of_unlading'].map(port_unlading_mapping)\n",
    "    df['arrival_id'] = df['actual_arrival_date'].map(arrival_mapping)\n",
    "    df['estimated_arrival_id'] = df['estimated_arrival_date'].map(estimated_arrival_mapping)\n",
    "    df['weight_id'] = df['weight'].map(weight_mapping)\n",
    "    df['manifest_quantity_id'] = df['manifest_quantity'].map(manifest_unit_mapping)\n",
    "    df['weight_unit_id'] = df['weight_unit'].map(weight_unit_mapping)\n",
    "    df = df.drop(columns=['vessel_name','port_of_unlading','measurement_unit','foreign_port_of_destination','estimated_arrival_date','foreign_port_of_lading','manifest_quantity','manifest_unit','measurement','weight','weight_unit','port_of_destination','mode_of_transportation','actual_arrival_date'])\n",
    "    df.to_csv(f'header_table{idx}.csv',index=False)\n",
    "    idx +=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
